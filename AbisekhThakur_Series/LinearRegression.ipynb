{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "statistical-cylinder",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "enhanced-director",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset:\n",
    "    def __init__(self,data,targets):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        current_sample = self.data[idx]\n",
    "        current_target = self.targets[idx]\n",
    "        \n",
    "        return{\n",
    "            \"x\": torch.tensor(current_sample),\n",
    "            \"y\": torch.tensor(current_target)\n",
    "        }    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "exceptional-silence",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, targets = make_classification(n_samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "sunrise-unknown",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,test_data, train_targets,test_targets = train_test_split(\n",
    "   data,\n",
    "   targets,\n",
    "   stratify = targets\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "raised-egypt",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making dataset object to load the training and testing data into memory \n",
    "\n",
    "training_dataset = CustomDataset(train_data, train_targets)\n",
    "testing_dataset = CustomDataset(test_data, test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "auburn-heather",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making dataloader object to serve the dataset in batches\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(training_dataset,\n",
    "                                           batch_size = 4, num_workers = 2)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(testing_dataset, \n",
    "                                          batch_size = 4, num_workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "thick-scale",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lambda x,W,b : torch.matmul(x,W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "endless-monte",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2009],\n",
       "        [-0.8478],\n",
       "        [-0.6741],\n",
       "        [ 0.2303],\n",
       "        [-1.3980],\n",
       "        [-0.2925],\n",
       "        [-0.2417],\n",
       "        [ 0.2103],\n",
       "        [-1.5155],\n",
       "        [ 1.7513],\n",
       "        [ 1.0913],\n",
       "        [ 1.3428],\n",
       "        [ 0.0895],\n",
       "        [-0.3812],\n",
       "        [ 1.2632],\n",
       "        [-0.7757],\n",
       "        [ 1.2971],\n",
       "        [ 0.5324],\n",
       "        [-0.4847],\n",
       "        [ 0.2335]], requires_grad=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = torch.randn(20,1,requires_grad = True) # Adding weight\n",
    "b = torch.randn(1,requires_grad =True) # Adding biases\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "starting-alloy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.7132], requires_grad=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "terminal-session",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 20])\n",
      "torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "for data in train_loader :\n",
    "    xtrain = data[\"x\"]\n",
    "    print (xtrain.shape)\n",
    "    ytrain = data[\"y\"]\n",
    "    print (ytrain.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "native-velvet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 20])\n",
      "torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "for test_data in test_loader :\n",
    "    xtest = test_data[\"x\"]\n",
    "    print (xtrain.shape)\n",
    "    ytest = test_data[\"y\"]\n",
    "    print (ytrain.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "breathing-delaware",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0439],\n",
      "        [-0.0387],\n",
      "        [ 0.0582],\n",
      "        [ 0.1234],\n",
      "        [ 0.4087],\n",
      "        [-0.2243],\n",
      "        [-0.3324],\n",
      "        [-0.0238],\n",
      "        [ 0.0288],\n",
      "        [-0.0962],\n",
      "        [-0.1870],\n",
      "        [ 0.3588],\n",
      "        [ 0.0627],\n",
      "        [-0.1244],\n",
      "        [ 0.0187],\n",
      "        [-0.0120],\n",
      "        [-0.1788],\n",
      "        [-0.1710],\n",
      "        [-0.2844],\n",
      "        [ 0.0999]])\n",
      "tensor([-0.1095])\n",
      "0 0.019577698782086372\n",
      "tensor([[-0.0427],\n",
      "        [-0.0379],\n",
      "        [ 0.0574],\n",
      "        [ 0.1211],\n",
      "        [ 0.4006],\n",
      "        [-0.2204],\n",
      "        [-0.3259],\n",
      "        [-0.0238],\n",
      "        [ 0.0286],\n",
      "        [-0.0948],\n",
      "        [-0.1835],\n",
      "        [ 0.3525],\n",
      "        [ 0.0615],\n",
      "        [-0.1220],\n",
      "        [ 0.0183],\n",
      "        [-0.0125],\n",
      "        [-0.1757],\n",
      "        [-0.1687],\n",
      "        [-0.2788],\n",
      "        [ 0.0977]])\n",
      "tensor([-0.1070])\n",
      "1 0.018876170739531517\n",
      "tensor([[-0.0414],\n",
      "        [-0.0371],\n",
      "        [ 0.0566],\n",
      "        [ 0.1189],\n",
      "        [ 0.3927],\n",
      "        [-0.2167],\n",
      "        [-0.3195],\n",
      "        [-0.0237],\n",
      "        [ 0.0284],\n",
      "        [-0.0935],\n",
      "        [-0.1800],\n",
      "        [ 0.3463],\n",
      "        [ 0.0603],\n",
      "        [-0.1197],\n",
      "        [ 0.0179],\n",
      "        [-0.0130],\n",
      "        [-0.1727],\n",
      "        [-0.1664],\n",
      "        [-0.2733],\n",
      "        [ 0.0956]])\n",
      "tensor([-0.1046])\n",
      "2 0.018200471997261047\n",
      "tensor([[-0.0402],\n",
      "        [-0.0364],\n",
      "        [ 0.0558],\n",
      "        [ 0.1167],\n",
      "        [ 0.3850],\n",
      "        [-0.2130],\n",
      "        [-0.3132],\n",
      "        [-0.0237],\n",
      "        [ 0.0282],\n",
      "        [-0.0921],\n",
      "        [-0.1765],\n",
      "        [ 0.3403],\n",
      "        [ 0.0591],\n",
      "        [-0.1174],\n",
      "        [ 0.0176],\n",
      "        [-0.0135],\n",
      "        [-0.1697],\n",
      "        [-0.1642],\n",
      "        [-0.2679],\n",
      "        [ 0.0935]])\n",
      "tensor([-0.1022])\n",
      "3 0.017549702897667885\n",
      "tensor([[-0.0390],\n",
      "        [-0.0357],\n",
      "        [ 0.0550],\n",
      "        [ 0.1145],\n",
      "        [ 0.3774],\n",
      "        [-0.2094],\n",
      "        [-0.3071],\n",
      "        [-0.0236],\n",
      "        [ 0.0280],\n",
      "        [-0.0908],\n",
      "        [-0.1731],\n",
      "        [ 0.3343],\n",
      "        [ 0.0580],\n",
      "        [-0.1151],\n",
      "        [ 0.0172],\n",
      "        [-0.0140],\n",
      "        [-0.1668],\n",
      "        [-0.1620],\n",
      "        [-0.2626],\n",
      "        [ 0.0914]])\n",
      "tensor([-0.0999])\n",
      "4 0.0169229693710804\n",
      "tensor([[-0.0378],\n",
      "        [-0.0349],\n",
      "        [ 0.0543],\n",
      "        [ 0.1124],\n",
      "        [ 0.3700],\n",
      "        [-0.2058],\n",
      "        [-0.3011],\n",
      "        [-0.0236],\n",
      "        [ 0.0278],\n",
      "        [-0.0895],\n",
      "        [-0.1698],\n",
      "        [ 0.3285],\n",
      "        [ 0.0568],\n",
      "        [-0.1129],\n",
      "        [ 0.0168],\n",
      "        [-0.0145],\n",
      "        [-0.1639],\n",
      "        [-0.1598],\n",
      "        [-0.2575],\n",
      "        [ 0.0894]])\n",
      "tensor([-0.0976])\n",
      "5 0.01631924882531166\n",
      "tensor([[-0.0366],\n",
      "        [-0.0342],\n",
      "        [ 0.0535],\n",
      "        [ 0.1103],\n",
      "        [ 0.3627],\n",
      "        [-0.2024],\n",
      "        [-0.2952],\n",
      "        [-0.0235],\n",
      "        [ 0.0276],\n",
      "        [-0.0883],\n",
      "        [-0.1666],\n",
      "        [ 0.3228],\n",
      "        [ 0.0557],\n",
      "        [-0.1108],\n",
      "        [ 0.0165],\n",
      "        [-0.0149],\n",
      "        [-0.1611],\n",
      "        [-0.1577],\n",
      "        [-0.2524],\n",
      "        [ 0.0874]])\n",
      "tensor([-0.0953])\n",
      "6 0.015737779438495636\n",
      "tensor([[-0.0355],\n",
      "        [-0.0335],\n",
      "        [ 0.0528],\n",
      "        [ 0.1083],\n",
      "        [ 0.3555],\n",
      "        [-0.1989],\n",
      "        [-0.2894],\n",
      "        [-0.0234],\n",
      "        [ 0.0274],\n",
      "        [-0.0870],\n",
      "        [-0.1634],\n",
      "        [ 0.3172],\n",
      "        [ 0.0546],\n",
      "        [-0.1087],\n",
      "        [ 0.0162],\n",
      "        [-0.0153],\n",
      "        [-0.1583],\n",
      "        [-0.1556],\n",
      "        [-0.2474],\n",
      "        [ 0.0854]])\n",
      "tensor([-0.0931])\n",
      "7 0.015177719295024872\n",
      "tensor([[-0.0344],\n",
      "        [-0.0329],\n",
      "        [ 0.0521],\n",
      "        [ 0.1063],\n",
      "        [ 0.3485],\n",
      "        [-0.1956],\n",
      "        [-0.2837],\n",
      "        [-0.0234],\n",
      "        [ 0.0272],\n",
      "        [-0.0858],\n",
      "        [-0.1603],\n",
      "        [ 0.3117],\n",
      "        [ 0.0536],\n",
      "        [-0.1066],\n",
      "        [ 0.0158],\n",
      "        [-0.0157],\n",
      "        [-0.1556],\n",
      "        [-0.1535],\n",
      "        [-0.2425],\n",
      "        [ 0.0835]])\n",
      "tensor([-0.0909])\n",
      "8 0.014638333581387997\n",
      "tensor([[-0.0334],\n",
      "        [-0.0322],\n",
      "        [ 0.0514],\n",
      "        [ 0.1043],\n",
      "        [ 0.3416],\n",
      "        [-0.1923],\n",
      "        [-0.2781],\n",
      "        [-0.0233],\n",
      "        [ 0.0270],\n",
      "        [-0.0846],\n",
      "        [-0.1572],\n",
      "        [ 0.3062],\n",
      "        [ 0.0525],\n",
      "        [-0.1045],\n",
      "        [ 0.0155],\n",
      "        [-0.0161],\n",
      "        [-0.1529],\n",
      "        [-0.1515],\n",
      "        [-0.2378],\n",
      "        [ 0.0817]])\n",
      "tensor([-0.0888])\n",
      "9 0.014118689112365246\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "for epoch in range(10):\n",
    "    epoch_loss = 0\n",
    "    counter = 0\n",
    "    for data in train_loader :\n",
    "#         print (data[\"x\"])\n",
    "        xtrain = data[\"x\"]\n",
    "        ytrain = data[\"y\"]\n",
    "        \n",
    "        output = model(xtrain.float(),W,b)\n",
    "        loss = torch.mean((ytrain.view(-1) - output.view(-1))**2)\n",
    "        epoch_loss = epoch_loss + loss.item()\n",
    "#         print(W.grad)\n",
    "#         print(b.grad)\n",
    "        loss.backward()\n",
    "#         print(W.grad)\n",
    "#         print(b.grad)\n",
    "        #update weight and biases\n",
    "        with torch.no_grad():\n",
    "            W = W - learning_rate * W.grad\n",
    "            b = b - learning_rate * b.grad\n",
    "            \n",
    "        W.requires_grad_(True)\n",
    "        b.requires_grad_(True)\n",
    "        counter += 1\n",
    "        \n",
    "        print(epoch,epoch_loss/counter)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "vertical-gibraltar",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []\n",
    "labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        xtest = data[\"x\"]\n",
    "        ytest = data[\"y\"]\n",
    "        \n",
    "        output = model(xtest.float(), W,b)\n",
    "        labels.append(ytest)\n",
    "        outputs.append(output)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "technological-valuation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.964032"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.roc_auc_score(torch.cat(labels).view(-1),torch.cat(outputs).view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "casual-copper",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
