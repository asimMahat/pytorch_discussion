{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "alternate-inside",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "perfect-brown",
   "metadata": {},
   "outputs": [],
   "source": [
    "class customDataset:\n",
    "    \n",
    "    def __init__(self,data,targets):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        current_sample = self.data[idx,:] \n",
    "        current_target = self.targets[idx]\n",
    "        \n",
    "        return{\n",
    "            \"sample\" : torch.tensor(current_sample, dtype = torch.float),\n",
    "            \"target\" : torch.tensor(current_target, dtype= torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "occasional-archives",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mmake_classification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_informative\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_redundant\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_repeated\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_clusters_per_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mflip_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mclass_sep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mhypercube\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mshift\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Generate a random n-class classification problem.\n",
       "\n",
       "This initially creates clusters of points normally distributed (std=1)\n",
       "about vertices of an ``n_informative``-dimensional hypercube with sides of\n",
       "length ``2*class_sep`` and assigns an equal number of clusters to each\n",
       "class. It introduces interdependence between these features and adds\n",
       "various types of further noise to the data.\n",
       "\n",
       "Without shuffling, ``X`` horizontally stacks features in the following\n",
       "order: the primary ``n_informative`` features, followed by ``n_redundant``\n",
       "linear combinations of the informative features, followed by ``n_repeated``\n",
       "duplicates, drawn randomly with replacement from the informative and\n",
       "redundant features. The remaining features are filled with random noise.\n",
       "Thus, without shuffling, all useful features are contained in the columns\n",
       "``X[:, :n_informative + n_redundant + n_repeated]``.\n",
       "\n",
       "Read more in the :ref:`User Guide <sample_generators>`.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "n_samples : int, default=100\n",
       "    The number of samples.\n",
       "\n",
       "n_features : int, default=20\n",
       "    The total number of features. These comprise ``n_informative``\n",
       "    informative features, ``n_redundant`` redundant features,\n",
       "    ``n_repeated`` duplicated features and\n",
       "    ``n_features-n_informative-n_redundant-n_repeated`` useless features\n",
       "    drawn at random.\n",
       "\n",
       "n_informative : int, default=2\n",
       "    The number of informative features. Each class is composed of a number\n",
       "    of gaussian clusters each located around the vertices of a hypercube\n",
       "    in a subspace of dimension ``n_informative``. For each cluster,\n",
       "    informative features are drawn independently from  N(0, 1) and then\n",
       "    randomly linearly combined within each cluster in order to add\n",
       "    covariance. The clusters are then placed on the vertices of the\n",
       "    hypercube.\n",
       "\n",
       "n_redundant : int, default=2\n",
       "    The number of redundant features. These features are generated as\n",
       "    random linear combinations of the informative features.\n",
       "\n",
       "n_repeated : int, default=0\n",
       "    The number of duplicated features, drawn randomly from the informative\n",
       "    and the redundant features.\n",
       "\n",
       "n_classes : int, default=2\n",
       "    The number of classes (or labels) of the classification problem.\n",
       "\n",
       "n_clusters_per_class : int, default=2\n",
       "    The number of clusters per class.\n",
       "\n",
       "weights : array-like of shape (n_classes,) or (n_classes - 1,),              default=None\n",
       "    The proportions of samples assigned to each class. If None, then\n",
       "    classes are balanced. Note that if ``len(weights) == n_classes - 1``,\n",
       "    then the last class weight is automatically inferred.\n",
       "    More than ``n_samples`` samples may be returned if the sum of\n",
       "    ``weights`` exceeds 1. Note that the actual class proportions will\n",
       "    not exactly match ``weights`` when ``flip_y`` isn't 0.\n",
       "\n",
       "flip_y : float, default=0.01\n",
       "    The fraction of samples whose class is assigned randomly. Larger\n",
       "    values introduce noise in the labels and make the classification\n",
       "    task harder. Note that the default setting flip_y > 0 might lead\n",
       "    to less than ``n_classes`` in y in some cases.\n",
       "\n",
       "class_sep : float, default=1.0\n",
       "    The factor multiplying the hypercube size.  Larger values spread\n",
       "    out the clusters/classes and make the classification task easier.\n",
       "\n",
       "hypercube : bool, default=True\n",
       "    If True, the clusters are put on the vertices of a hypercube. If\n",
       "    False, the clusters are put on the vertices of a random polytope.\n",
       "\n",
       "shift : float, ndarray of shape (n_features,) or None, default=0.0\n",
       "    Shift features by the specified value. If None, then features\n",
       "    are shifted by a random value drawn in [-class_sep, class_sep].\n",
       "\n",
       "scale : float, ndarray of shape (n_features,) or None, default=1.0\n",
       "    Multiply features by the specified value. If None, then features\n",
       "    are scaled by a random value drawn in [1, 100]. Note that scaling\n",
       "    happens after shifting.\n",
       "\n",
       "shuffle : bool, default=True\n",
       "    Shuffle the samples and the features.\n",
       "\n",
       "random_state : int, RandomState instance or None, default=None\n",
       "    Determines random number generation for dataset creation. Pass an int\n",
       "    for reproducible output across multiple function calls.\n",
       "    See :term:`Glossary <random_state>`.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "X : ndarray of shape (n_samples, n_features)\n",
       "    The generated samples.\n",
       "\n",
       "y : ndarray of shape (n_samples,)\n",
       "    The integer labels for class membership of each sample.\n",
       "\n",
       "Notes\n",
       "-----\n",
       "The algorithm is adapted from Guyon [1] and was designed to generate\n",
       "the \"Madelon\" dataset.\n",
       "\n",
       "References\n",
       "----------\n",
       ".. [1] I. Guyon, \"Design of experiments for the NIPS 2003 variable\n",
       "       selection benchmark\", 2003.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "make_blobs : Simplified variant.\n",
       "make_multilabel_classification : Unrelated generator for multilabel tasks.\n",
       "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/envs/vector/lib/python3.8/site-packages/sklearn/datasets/_samples_generator.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "received-helping",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, targets = make_classification (n_samples = 1000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "laughing-representation",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = customDataset(data=data, targets=targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "satisfactory-geology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "regulated-parks",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Data loader. Combines a dataset and a sampler, and provides an iterable over\n",
       "the given dataset.\n",
       "\n",
       "The :class:`~torch.utils.data.DataLoader` supports both map-style and\n",
       "iterable-style datasets with single- or multi-process loading, customizing\n",
       "loading order and optional automatic batching (collation) and memory pinning.\n",
       "\n",
       "See :py:mod:`torch.utils.data` documentation page for more details.\n",
       "\n",
       "Args:\n",
       "    dataset (Dataset): dataset from which to load the data.\n",
       "    batch_size (int, optional): how many samples per batch to load\n",
       "        (default: ``1``).\n",
       "    shuffle (bool, optional): set to ``True`` to have the data reshuffled\n",
       "        at every epoch (default: ``False``).\n",
       "    sampler (Sampler or Iterable, optional): defines the strategy to draw\n",
       "        samples from the dataset. Can be any ``Iterable`` with ``__len__``\n",
       "        implemented. If specified, :attr:`shuffle` must not be specified.\n",
       "    batch_sampler (Sampler or Iterable, optional): like :attr:`sampler`, but\n",
       "        returns a batch of indices at a time. Mutually exclusive with\n",
       "        :attr:`batch_size`, :attr:`shuffle`, :attr:`sampler`,\n",
       "        and :attr:`drop_last`.\n",
       "    num_workers (int, optional): how many subprocesses to use for data\n",
       "        loading. ``0`` means that the data will be loaded in the main process.\n",
       "        (default: ``0``)\n",
       "    collate_fn (callable, optional): merges a list of samples to form a\n",
       "        mini-batch of Tensor(s).  Used when using batched loading from a\n",
       "        map-style dataset.\n",
       "    pin_memory (bool, optional): If ``True``, the data loader will copy Tensors\n",
       "        into CUDA pinned memory before returning them.  If your data elements\n",
       "        are a custom type, or your :attr:`collate_fn` returns a batch that is a custom type,\n",
       "        see the example below.\n",
       "    drop_last (bool, optional): set to ``True`` to drop the last incomplete batch,\n",
       "        if the dataset size is not divisible by the batch size. If ``False`` and\n",
       "        the size of dataset is not divisible by the batch size, then the last batch\n",
       "        will be smaller. (default: ``False``)\n",
       "    timeout (numeric, optional): if positive, the timeout value for collecting a batch\n",
       "        from workers. Should always be non-negative. (default: ``0``)\n",
       "    worker_init_fn (callable, optional): If not ``None``, this will be called on each\n",
       "        worker subprocess with the worker id (an int in ``[0, num_workers - 1]``) as\n",
       "        input, after seeding and before data loading. (default: ``None``)\n",
       "    prefetch_factor (int, optional, keyword-only arg): Number of samples loaded\n",
       "        in advance by each worker. ``2`` means there will be a total of\n",
       "        2 * num_workers samples prefetched across all workers. (default: ``2``)\n",
       "    persistent_workers (bool, optional): If ``True``, the data loader will not shutdown\n",
       "        the worker processes after a dataset has been consumed once. This allows to\n",
       "        maintain the workers `Dataset` instances alive. (default: ``False``)\n",
       "\n",
       "\n",
       ".. warning:: If the ``spawn`` start method is used, :attr:`worker_init_fn`\n",
       "             cannot be an unpicklable object, e.g., a lambda function. See\n",
       "             :ref:`multiprocessing-best-practices` on more details related\n",
       "             to multiprocessing in PyTorch.\n",
       "\n",
       ".. warning:: ``len(dataloader)`` heuristic is based on the length of the sampler used.\n",
       "             When :attr:`dataset` is an :class:`~torch.utils.data.IterableDataset`,\n",
       "             it instead returns an estimate based on ``len(dataset) / batch_size``, with proper\n",
       "             rounding depending on :attr:`drop_last`, regardless of multi-process loading\n",
       "             configurations. This represents the best guess PyTorch can make because PyTorch\n",
       "             trusts user :attr:`dataset` code in correctly handling multi-process\n",
       "             loading to avoid duplicate data.\n",
       "\n",
       "             However, if sharding results in multiple workers having incomplete last batches,\n",
       "             this estimate can still be inaccurate, because (1) an otherwise complete batch can\n",
       "             be broken into multiple ones and (2) more than one batch worth of samples can be\n",
       "             dropped when :attr:`drop_last` is set. Unfortunately, PyTorch can not detect such\n",
       "             cases in general.\n",
       "\n",
       "             See `Dataset Types`_ for more details on these two types of datasets and how\n",
       "             :class:`~torch.utils.data.IterableDataset` interacts with\n",
       "             `Multi-process data loading`_.\n",
       "\n",
       ".. warning:: See :ref:`reproducibility`, and :ref:`dataloader-workers-random-seed`, and\n",
       "             :ref:`data-loading-randomness` notes for random seed related questions.\n",
       "\u001b[0;31mFile:\u001b[0m           ~/anaconda3/envs/vector/lib/python3.8/site-packages/torch/utils/data/dataloader.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?torch.utils.data.DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bright-edmonton",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size =4, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "turned-assistant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f564363de20>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "structural-hierarchy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sample': tensor([[ 8.3735e-01, -4.8366e-01, -6.6673e-01,  1.5933e+00, -8.7035e-01,\n",
      "         -4.5924e-01, -8.3652e-01,  6.3112e-01, -2.5652e+00, -1.8522e+00,\n",
      "          2.2516e+00,  1.3232e+00, -4.8442e-01, -1.3356e+00,  8.2603e-04,\n",
      "         -2.0868e+00, -3.0918e-01, -5.6404e-01, -1.0970e+00,  7.9516e-01],\n",
      "        [-1.7613e-01, -7.1169e-02, -4.8296e-01,  1.0786e+00,  8.0644e-01,\n",
      "          1.4416e+00,  3.0945e-01, -4.1731e-01, -8.5254e-01,  1.1297e-02,\n",
      "          2.5435e-01, -3.1646e-01,  4.0313e-01,  9.9033e-01, -1.4868e+00,\n",
      "         -1.5921e+00,  5.5012e-01,  4.1444e-01, -5.6856e-01,  8.4732e-01],\n",
      "        [-5.3803e-01, -1.5773e+00,  5.7508e-01, -1.9418e+00,  1.3523e+00,\n",
      "         -2.9820e-01,  4.4954e-01,  9.8087e-01, -3.2040e-01, -1.4141e-01,\n",
      "          2.1788e-01, -6.5884e-01,  4.0197e-01,  1.7111e-02,  1.7433e-01,\n",
      "         -3.7589e-01,  2.0226e+00,  5.1999e-01, -1.9302e+00, -1.2147e+00],\n",
      "        [-8.1322e-01,  1.1522e+00, -2.9673e-01, -6.3718e-01,  1.5030e+00,\n",
      "         -1.0604e+00, -4.7348e-01, -2.7854e-01,  2.1471e-01, -4.9080e-02,\n",
      "         -8.7391e-01,  3.9561e-01, -7.2913e-01,  2.1021e+00,  4.5747e-01,\n",
      "         -1.0723e+00, -1.7461e+00, -1.3307e+00, -8.5877e-01,  2.3137e+00]]), 'target': tensor([0, 0, 0, 0])}\n",
      "torch.Size([4, 20])\n",
      "torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "for data in train_loader:\n",
    "    print(data)\n",
    "    print (data[\"sample\"].shape)\n",
    "    print(data[\"target\"].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "amino-means",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'samole'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-b4153b303e2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"samole\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"target\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'samole'"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    for data in train_loader:\n",
    "        sample = data[\"samole\"]\n",
    "        target = data[\"target\"]\n",
    "        outputs = model(x,y)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passing-memorial",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
